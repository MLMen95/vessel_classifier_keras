{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 total vessel categories.\n",
      "There are 9825 total vessel images.\n",
      "\n",
      "There are 7425 training vessel images.\n",
      "There are 1200 validation vessel images.\n",
      "There are 1200 test vessel images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as preprocess_input_vgg19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    ship_files = np.array(data['filenames'])\n",
    "    ship_targets = np_utils.to_categorical(np.array(data['target']), 12)\n",
    "    return ship_files, ship_targets\n",
    "\n",
    "train_files, train_targets = load_dataset('data/images/train')\n",
    "valid_files, valid_targets = load_dataset('data/images/valid')\n",
    "test_files, test_targets = load_dataset('data/images/test')\n",
    "\n",
    "ship_names = [item[20:-1] for item in sorted(glob(\"data/images/train/*/\"))]\n",
    "\n",
    "# Let's check the dataset\n",
    "print('There are %d total vessel categories.' % len(ship_names))\n",
    "print('There are %s total vessel images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training vessel images.' % len(train_files))\n",
    "print('There are %d validation vessel images.' % len(valid_files))\n",
    "print('There are %d test vessel images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7425/7425 [00:23<00:00, 317.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:17<00:00, 68.54it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:15<00:00, 79.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7425/7425 [01:33<00:00, 79.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:17<00:00, 67.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:16<00:00, 74.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19 shape (7, 7, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7425/7425 [01:34<00:00, 78.51it/s]\n",
      "d:\\mlproject\\vessel_classifier\\.venv\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:19<00:00, 60.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:16<00:00, 54.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 shape (7, 7, 2048)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 7, 7, 512)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 7, 7, 2048)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          65536       global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1048576     global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 128)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 640)          0           activation_148[0][0]             \n",
      "                                                                 activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 640)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 640)          409600      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 640)          2560        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 640)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 640)          0           activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12)           7692        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,536,524\n",
      "Trainable params: 1,533,964\n",
      "Non-trainable params: 2,560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#using machinememo blog to do prediction\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "def extract_VGG19(file_paths):\n",
    "    tensors = paths_to_tensor(file_paths).astype('float32')\n",
    "    preprocessed_input = preprocess_input_vgg19(tensors)\n",
    "    return VGG19(weights='imagenet', include_top=False).predict(preprocessed_input, batch_size=32)\n",
    "\n",
    "def extract_Resnet50(file_paths):\n",
    "    tensors = paths_to_tensor(file_paths).astype('float32')\n",
    "    preprocessed_input = preprocess_input_resnet50(tensors)\n",
    "    return ResNet50(weights='imagenet', include_top=False).predict(preprocessed_input, batch_size=32)\n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "\n",
    "train_vgg19 = extract_VGG19(train_files)\n",
    "valid_vgg19 = extract_VGG19(valid_files)\n",
    "test_vgg19 = extract_VGG19(test_files)\n",
    "print(\"VGG19 shape\", train_vgg19.shape[1:])\n",
    "\n",
    "train_resnet50 = extract_Resnet50(train_files)\n",
    "valid_resnet50 = extract_Resnet50(valid_files)\n",
    "test_resnet50 = extract_Resnet50(test_files)\n",
    "print(\"Resnet50 shape\", train_resnet50.shape[1:])\n",
    "\n",
    "def input_branch(input_shape=None):\n",
    "    \n",
    "    size = int(input_shape[2] / 4)\n",
    "    \n",
    "    branch_input = Input(shape=input_shape)\n",
    "    branch = GlobalAveragePooling2D()(branch_input)\n",
    "    branch = Dense(size, use_bias=False, kernel_initializer='uniform')(branch)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branch = Activation(\"relu\")(branch)\n",
    "    return branch, branch_input\n",
    "\n",
    "vgg19_branch, vgg19_input = input_branch(input_shape=(7, 7, 512))\n",
    "resnet50_branch, resnet50_input = input_branch(input_shape=(7, 7, 2048))\n",
    "concatenate_branches = Concatenate()([vgg19_branch, resnet50_branch])\n",
    "\n",
    "net = Dropout(0.3)(concatenate_branches)\n",
    "net = Dense(640, use_bias=False, kernel_initializer='uniform')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "net = Dropout(0.3)(net)\n",
    "net = Dense(12, kernel_initializer='uniform', activation=\"softmax\")(net)\n",
    "\n",
    "model = Model(inputs=[vgg19_input, resnet50_input], outputs=[net])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7425 samples, validate on 1200 samples\n",
      "Epoch 1/20\n",
      " - 42s - loss: 1.0584 - acc: 0.6778 - val_loss: 0.3550 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35503, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 2/20\n",
      " - 21s - loss: 0.8290 - acc: 0.7537 - val_loss: 0.2456 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35503 to 0.24561, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 3/20\n",
      " - 19s - loss: 0.7250 - acc: 0.7939 - val_loss: 0.2181 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24561 to 0.21808, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 4/20\n",
      " - 18s - loss: 0.6699 - acc: 0.8137 - val_loss: 0.1926 - val_acc: 0.9408\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21808 to 0.19257, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 5/20\n",
      " - 18s - loss: 0.6484 - acc: 0.8256 - val_loss: 0.1860 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.19257 to 0.18600, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 6/20\n",
      " - 18s - loss: 0.6111 - acc: 0.8408 - val_loss: 0.1899 - val_acc: 0.9417\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18600\n",
      "Epoch 7/20\n",
      " - 18s - loss: 0.5767 - acc: 0.8512 - val_loss: 0.1779 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18600 to 0.17790, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 8/20\n",
      " - 18s - loss: 0.5739 - acc: 0.8509 - val_loss: 0.1603 - val_acc: 0.9533\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.17790 to 0.16033, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 9/20\n",
      " - 18s - loss: 0.5528 - acc: 0.8594 - val_loss: 0.1797 - val_acc: 0.9433\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16033\n",
      "Epoch 10/20\n",
      " - 18s - loss: 0.5630 - acc: 0.8646 - val_loss: 0.1732 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16033\n",
      "Epoch 11/20\n",
      " - 18s - loss: 0.5310 - acc: 0.8663 - val_loss: 0.1664 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16033\n",
      "Epoch 12/20\n",
      " - 18s - loss: 0.5540 - acc: 0.8672 - val_loss: 0.1434 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.16033 to 0.14341, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 13/20\n",
      " - 18s - loss: 0.5171 - acc: 0.8716 - val_loss: 0.1414 - val_acc: 0.9600\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.14341 to 0.14142, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 14/20\n",
      " - 18s - loss: 0.4982 - acc: 0.8792 - val_loss: 0.1658 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.14142\n",
      "Epoch 15/20\n",
      " - 18s - loss: 0.5275 - acc: 0.8734 - val_loss: 0.1604 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.14142\n",
      "Epoch 16/20\n",
      " - 18s - loss: 0.4879 - acc: 0.8877 - val_loss: 0.1712 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.14142\n",
      "Epoch 17/20\n",
      " - 18s - loss: 0.5100 - acc: 0.8793 - val_loss: 0.1488 - val_acc: 0.9592\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.14142\n",
      "Epoch 18/20\n",
      " - 18s - loss: 0.4806 - acc: 0.8865 - val_loss: 0.1318 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.14142 to 0.13177, saving model to saved_models/bestmodel_new.hdf5\n",
      "Epoch 19/20\n",
      " - 18s - loss: 0.5158 - acc: 0.8803 - val_loss: 0.1547 - val_acc: 0.9617\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.13177\n",
      "Epoch 20/20\n",
      " - 18s - loss: 0.4633 - acc: 0.8896 - val_loss: 0.1616 - val_acc: 0.9575\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.13177\n",
      "Test accuracy: 96.1667%\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/bestmodel_new.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit([train_vgg19, train_resnet50], train_targets, \n",
    "          validation_data=([valid_vgg19, valid_resnet50], valid_targets),\n",
    "          epochs=20, batch_size=4, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "model.load_weights('saved_models/bestmodel_new.hdf5')\n",
    "\n",
    "predictions = model.predict([valid_vgg19, valid_resnet50])\n",
    "breed_predictions = [np.argmax(prediction) for prediction in predictions]\n",
    "breed_true_labels = [np.argmax(true_label) for true_label in test_targets]\n",
    "print('Test accuracy: %.4f%%' % (accuracy_score(breed_true_labels, breed_predictions) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fishing\n"
     ]
    }
   ],
   "source": [
    "img = path_to_tensor('data/images/doge.jpg')\n",
    "preprocessed_imgvgg = preprocess_input_vgg19(img)\n",
    "preprocessed_imgresnet = preprocess_input_resnet50(img)\n",
    "\n",
    "\n",
    "img_vgg19 = VGG19(weights='imagenet', include_top=False).predict(preprocessed_imgvgg, batch_size=32)\n",
    "img_resnet = ResNet50(weights='imagenet', include_top=False).predict(preprocessed_imgresnet, batch_size=32)\n",
    "\n",
    "classification = model.predict([img_vgg19, img_resnet])\n",
    "ship_names = [item[18:-1] for item in sorted(glob(\"data/images/train/*/\"))]\n",
    "print(ship_names[np.argmax(classification)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vgg16_resnet50_ship_model_combined.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('vgg16_resnet50_ship_model_combined.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
